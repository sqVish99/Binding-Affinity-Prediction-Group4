{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-14T03:09:47.237253Z",
     "iopub.status.busy": "2024-12-14T03:09:47.236795Z",
     "iopub.status.idle": "2024-12-14T03:10:07.021224Z",
     "shell.execute_reply": "2024-12-14T03:10:07.020275Z",
     "shell.execute_reply.started": "2024-12-14T03:09:47.237214Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from transformers import TFBertModel,BertModel, BertForPreTraining, BertTokenizer, BertConfig\n",
    "import torch\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"/kaggle/input/catelmo-bert-tiny/\", do_lower_case=False )\n",
    "model = BertModel.from_pretrained(\"/kaggle/input/catelmo-bert-tiny/\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "def pad_sequence(sequence, tokenizer, max_length=44):\n",
    "    seq = \" \".join(sequence)\n",
    "    # Padding/truncation using the tokenizer\n",
    "    tokens = tokenizer(seq, padding='max_length', truncation=True, max_length=max_length, return_tensors='pt')\n",
    "    return tokens['input_ids'].squeeze(0)\n",
    "\n",
    "def BERT_embedding(x, TOKENIZER, DEVICE, max_length=44, spad=True):\n",
    "    if spad:\n",
    "        padded_input = pad_sequence(x, tokenizer, max_length)\n",
    "        encoded_input = padded_input.unsqueeze(0).to(device)\n",
    "    else:\n",
    "        seq = \" \".join(x)\n",
    "        seq = re.sub(r\"[UZOB]\", \"X\", seq)\n",
    "        encoded_input = tokenizer(seq, return_tensors='pt').to(device)\n",
    "    if spad:\n",
    "        output = model(encoded_input) \n",
    "    else:\n",
    "        output = model(**encoded_input)\n",
    "    return output\n",
    "\n",
    "column_names = ['antigen', 'cdr3_sequence', 'class']\n",
    "dat = pd.read_csv('/kaggle/input/tcrdata/data/BAP/tcr_split/train.csv',header=None, names=column_names)\n",
    "dat['tcr_embeds'] = None\n",
    "dat['epi_embeds'] = None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T22:19:36.329062Z",
     "iopub.status.busy": "2024-12-13T22:19:36.328061Z",
     "iopub.status.idle": "2024-12-13T22:34:56.808013Z",
     "shell.execute_reply": "2024-12-13T22:34:56.807003Z",
     "shell.execute_reply.started": "2024-12-13T22:19:36.329023Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for i in tqdm(range(len(dat))):\n",
    "    # Generating embeddings using the BERT embedding function\n",
    "    epi_embed = BERT_embedding(dat.antigen[i], tokenizer, device,16, False)[0].reshape(-1,768).mean(dim=0).tolist()  # Assume shape (N, D) or (D,)\n",
    "    tcr_embed = BERT_embedding(dat.cdr3_sequence[i], tokenizer, device, 16, False)[0].reshape(-1,768).mean(dim=0).tolist()  # Assume shape (N, D) or (D,)\n",
    "    \n",
    "    # Saving embeddings as lists in the DataFrame\n",
    "    dat.at[i, 'epi_embeds'] = epi_embed\n",
    "    dat.at[i, 'tcr_embeds'] = tcr_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional: To save/load files\n",
    "# dat.to_pickle('/kaggle/input/bert-embeddings-catelmo/epi_train_tiny_embeddings_768.pkl')\n",
    "# dat.to_pickle('/kaggle/input/bert-embeddings-catelmo/epi_train_tiny_embeddings_768.pkl')\n",
    "# dat = pd.read_pickle('/kaggle/input/bert-embeddings-catelmo/epi_train_tiny_embeddings_768.pkl')\n",
    "# dat2 = pd.read_pickle('/kaggle/input/bert-embeddings-catelmo/epi_test_tiny_embeddings_768.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-14T03:10:57.870160Z",
     "iopub.status.busy": "2024-12-14T03:10:57.869929Z",
     "iopub.status.idle": "2024-12-14T03:10:57.888431Z",
     "shell.execute_reply": "2024-12-14T03:10:57.887570Z",
     "shell.execute_reply.started": "2024-12-14T03:10:57.870137Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "tcr_embeds = dat['tcr_embeds'].tolist()\n",
    "epi_embeds = dat['epi_embeds'].tolist()\n",
    "labels = dat['class'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-14T03:00:04.367871Z",
     "iopub.status.busy": "2024-12-14T03:00:04.367304Z",
     "iopub.status.idle": "2024-12-14T03:00:10.084688Z",
     "shell.execute_reply": "2024-12-14T03:00:10.083791Z",
     "shell.execute_reply.started": "2024-12-14T03:00:04.367827Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define the model\n",
    "class CombinedModel(nn.Module):\n",
    "    def __init__(self, size):\n",
    "        super(CombinedModel, self).__init__()\n",
    "        self.n_dim = size\n",
    "        \n",
    "        self.branchA = nn.Sequential(\n",
    "            nn.Linear(self.n_dim, self.n_dim*2),\n",
    "            nn.BatchNorm1d(self.n_dim*2),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.SiLU()\n",
    "        )\n",
    "        \n",
    "        self.branchB = nn.Sequential(\n",
    "            nn.Linear(self.n_dim, self.n_dim*2),\n",
    "            nn.BatchNorm1d(self.n_dim*2),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.SiLU()\n",
    "        )\n",
    "        \n",
    "        self.combined = nn.Sequential(\n",
    "            nn.Linear(self.n_dim*2 * 2, self.n_dim),\n",
    "            nn.BatchNorm1d(self.n_dim),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(self.n_dim, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, inputA, inputB):\n",
    "        x = self.branchA(inputA)\n",
    "        y = self.branchB(inputB)\n",
    "        combined = torch.cat((x, y), dim=1)\n",
    "        z = self.combined(combined)\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-14T03:00:10.086451Z",
     "iopub.status.busy": "2024-12-14T03:00:10.086031Z",
     "iopub.status.idle": "2024-12-14T03:00:10.092193Z",
     "shell.execute_reply": "2024-12-14T03:00:10.091217Z",
     "shell.execute_reply.started": "2024-12-14T03:00:10.086421Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class TCRDataset(Dataset):\n",
    "    def __init__(self, tcr_embeds, epi_embeds, labels):\n",
    "        self.tcr_embeds = tcr_embeds\n",
    "        self.epi_embeds = epi_embeds\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.tcr_embeds[idx], dtype=torch.float32), \\\n",
    "               torch.tensor(self.epi_embeds[idx], dtype=torch.float32), \\\n",
    "               torch.tensor(self.labels[idx], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-14T03:00:12.911220Z",
     "iopub.status.busy": "2024-12-14T03:00:12.910821Z",
     "iopub.status.idle": "2024-12-14T03:00:12.921423Z",
     "shell.execute_reply": "2024-12-14T03:00:12.920184Z",
     "shell.execute_reply.started": "2024-12-14T03:00:12.911186Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_dataset = TCRDataset(dat['tcr_embeds'].tolist(),\n",
    "                          dat['epi_embeds'].tolist(),\n",
    "                          dat['class'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-14T03:00:16.400781Z",
     "iopub.status.busy": "2024-12-14T03:00:16.400385Z",
     "iopub.status.idle": "2024-12-14T03:00:16.409228Z",
     "shell.execute_reply": "2024-12-14T03:00:16.408055Z",
     "shell.execute_reply.started": "2024-12-14T03:00:16.400746Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_dataset = TCRDataset(tcr_embeds = dat2['tcr_embeds'].tolist(),\n",
    "                            epi_embeds = dat2['epi_embeds'].tolist(),\n",
    "                            labels = dat2['class'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-14T03:02:23.319979Z",
     "iopub.status.busy": "2024-12-14T03:02:23.319615Z",
     "iopub.status.idle": "2024-12-14T03:06:23.822720Z",
     "shell.execute_reply": "2024-12-14T03:06:23.821529Z",
     "shell.execute_reply.started": "2024-12-14T03:02:23.319949Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "FFnmodel = CombinedModel(768).to(device)\n",
    "optimizer = torch.optim.Adam(FFnmodel.parameters(), lr=0.001)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(5): \n",
    "    FFnmodel.train()\n",
    "    epoch_loss = 0\n",
    "    train_preds, train_labels = [], []\n",
    "    \n",
    "    for tcr, epi, label in tqdm(train_loader, desc=f\"Epoch {epoch+1}\"):\n",
    "        tcr, epi, label = tcr.to(device), epi.to(device), label.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = FFnmodel(tcr, epi).squeeze()\n",
    "        loss = criterion(outputs, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        train_preds.extend(outputs.detach().cpu().numpy())\n",
    "        train_labels.extend(label.cpu().numpy())\n",
    "\n",
    "    # Metrics\n",
    "    train_preds_binary = [1 if p >= 0.5 else 0 for p in train_preds]\n",
    "    acc = accuracy_score(train_labels, train_preds_binary)\n",
    "    prec = precision_score(train_labels, train_preds_binary)\n",
    "    rec = recall_score(train_labels, train_preds_binary)\n",
    "    auc = roc_auc_score(train_labels, train_preds)\n",
    "\n",
    "    print(f\"Epoch {epoch+1} - Loss: {epoch_loss/len(train_loader):.4f}, Acc: {acc:.4f}, Prec: {prec:.4f}, Rec: {rec:.4f}, AUC: {auc:.4f}\")\n",
    "\n",
    "# Save the trained model\n",
    "model_save_path = 'FFnmodel_weights.pth'\n",
    "torch.save(FFnmodel.state_dict(), model_save_path)\n",
    "print(f\"Model saved to {model_save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-14T03:08:39.496148Z",
     "iopub.status.busy": "2024-12-14T03:08:39.495466Z",
     "iopub.status.idle": "2024-12-14T03:08:54.155611Z",
     "shell.execute_reply": "2024-12-14T03:08:54.154563Z",
     "shell.execute_reply.started": "2024-12-14T03:08:39.496110Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "FFnmodel.eval()\n",
    "test_preds, test_labels = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for tcr, epi, label in tqdm(test_loader, desc=\"Testing\"):\n",
    "        tcr, epi, label = tcr.to(device), epi.to(device), label.to(device)\n",
    "        outputs = FFnmodel(tcr, epi).squeeze()\n",
    "        test_preds.extend(outputs.cpu().numpy())\n",
    "        test_labels.extend(label.cpu().numpy())\n",
    "\n",
    "# Test metrics\n",
    "test_preds_binary = [1 if p >= 0.5 else 0 for p in test_preds]\n",
    "acc = accuracy_score(test_labels, test_preds_binary)\n",
    "prec = precision_score(test_labels, test_preds_binary)\n",
    "rec = recall_score(test_labels, test_preds_binary)\n",
    "auc = roc_auc_score(test_labels, test_preds)\n",
    "\n",
    "print(f\"Test Metrics - Acc: {acc:.4f}, Prec: {prec:.4f}, Rec: {rec:.4f}, AUC: {auc:.4f}\")\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'True_Labels': test_labels,\n",
    "    'Predicted_Scores': test_preds,\n",
    "    'Predicted_Binary': test_preds_binary\n",
    "})\n",
    "\n",
    "csv_filename = 'base_epi_test_predictions.csv'\n",
    "df.to_csv(csv_filename, index=False)\n",
    "\n",
    "print(f\"Predictions and labels saved to: {csv_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-14T01:03:56.213721Z",
     "iopub.status.busy": "2024-12-14T01:03:56.212950Z",
     "iopub.status.idle": "2024-12-14T01:03:59.010062Z",
     "shell.execute_reply": "2024-12-14T01:03:59.009330Z",
     "shell.execute_reply.started": "2024-12-14T01:03:56.213668Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Subset, DataLoader\n",
    "from sklearn.model_selection import ParameterGrid, KFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "def hyperparameter_tuning(dat, model_class, device, param_grid=None, num_folds=5):\n",
    "    \"\"\"\n",
    "    Perform hyperparameter tuning using grid search with cross-validation\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    dat : pandas.DataFrame\n",
    "        DataFrame containing TCR and epitope embeddings and labels\n",
    "    model_class : class\n",
    "        PyTorch model class to be tuned\n",
    "    device : torch.device\n",
    "        Device to run the model on (cuda/cpu)\n",
    "    param_grid : dict, optional\n",
    "        Dictionary of hyperparameters to tune. Default is a predefined grid\n",
    "    num_folds : int, optional\n",
    "        Number of folds for cross-validation (default: 5)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Best hyperparameters and corresponding performance metrics\n",
    "    \"\"\"\n",
    "    # Default parameter grid if not provided\n",
    "    if param_grid is None:\n",
    "        param_grid = {\n",
    "            'learning_rate': [0.001, 0.005, 0.01],\n",
    "            'batch_size': [16, 32, 64],\n",
    "            'dropout_rate': [0.2, 0.3, 0.4],\n",
    "            'hidden_multiplier': [1, 2, 4],\n",
    "            'epochs': [3, 5, 7]\n",
    "        }\n",
    "    \n",
    "    # Prepare full dataset\n",
    "    full_dataset = TCRDataset(\n",
    "        dat['tcr_embeds'].tolist(),\n",
    "        dat['epi_embeds'].tolist(),\n",
    "        dat['class'].tolist()\n",
    "    )\n",
    "    \n",
    "    # Initialize tracking for best hyperparameters\n",
    "    best_params = None\n",
    "    best_avg_auc = 0\n",
    "    all_results = []\n",
    "    \n",
    "    # Generate all combinations of hyperparameters\n",
    "    param_combinations = list(ParameterGrid(param_grid))\n",
    "    \n",
    "    for params in param_combinations:\n",
    "        print(\"\\nTesting Hyperparameters:\")\n",
    "        for k, v in params.items():\n",
    "            print(f\"{k}: {v}\")\n",
    "        \n",
    "        # Prepare cross-validation\n",
    "        kfold = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "        \n",
    "        fold_metrics = {\n",
    "            'accuracies': [],\n",
    "            'precisions': [],\n",
    "            'recalls': [],\n",
    "            'aucs': []\n",
    "        }\n",
    "        \n",
    "        for fold, (train_idx, val_idx) in enumerate(kfold.split(full_dataset), 1):\n",
    "            # Prepare datasets for this fold\n",
    "            train_dataset = Subset(full_dataset, train_idx)\n",
    "            val_dataset = Subset(full_dataset, val_idx)\n",
    "            \n",
    "            train_loader = DataLoader(train_dataset, batch_size=params['batch_size'], shuffle=True)\n",
    "            val_loader = DataLoader(val_dataset, batch_size=params['batch_size'], shuffle=False)\n",
    "            \n",
    "            # Modify model to incorporate dropout rate and hidden layer multiplier\n",
    "            class TunedCombinedModel(CombinedModel):\n",
    "                def __init__(self, size):\n",
    "                    super().__init__(size)\n",
    "                    # Modify dropout and hidden layer sizes based on tuning parameters\n",
    "                    dropout_rate = params.get('dropout_rate', 0.3)\n",
    "                    hidden_multiplier = params.get('hidden_multiplier', 2)\n",
    "                    \n",
    "                    self.branchA = nn.Sequential(\n",
    "                        nn.Linear(self.n_dim, self.n_dim * hidden_multiplier),\n",
    "                        nn.BatchNorm1d(self.n_dim * hidden_multiplier),\n",
    "                        nn.Dropout(dropout_rate),\n",
    "                        nn.SiLU()\n",
    "                    )\n",
    "                    \n",
    "                    self.branchB = nn.Sequential(\n",
    "                        nn.Linear(self.n_dim, self.n_dim * hidden_multiplier),\n",
    "                        nn.BatchNorm1d(self.n_dim * hidden_multiplier),\n",
    "                        nn.Dropout(dropout_rate),\n",
    "                        nn.SiLU()\n",
    "                    )\n",
    "                    \n",
    "                    self.combined = nn.Sequential(\n",
    "                        nn.Linear(self.n_dim * hidden_multiplier * 2, self.n_dim),\n",
    "                        nn.BatchNorm1d(self.n_dim),\n",
    "                        nn.Dropout(dropout_rate),\n",
    "                        nn.SiLU(),\n",
    "                        nn.Linear(self.n_dim, 1),\n",
    "                        nn.Sigmoid()\n",
    "                    )\n",
    "            \n",
    "            # Initialize model and optimizer\n",
    "            FFnmodel = TunedCombinedModel(768).to(device)\n",
    "            optimizer = torch.optim.Adam(FFnmodel.parameters(), lr=params['learning_rate'])\n",
    "            criterion = nn.BCELoss()\n",
    "            \n",
    "            # Training loop\n",
    "            for epoch in range(params['epochs']):\n",
    "                FFnmodel.train()\n",
    "                epoch_loss = 0\n",
    "                \n",
    "                for tcr, epi, label in train_loader:\n",
    "                    tcr, epi, label = tcr.to(device), epi.to(device), label.to(device)\n",
    "                    \n",
    "                    optimizer.zero_grad()\n",
    "                    outputs = FFnmodel(tcr, epi).squeeze()\n",
    "                    loss = criterion(outputs, label)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    \n",
    "                    epoch_loss += loss.item()\n",
    "            \n",
    "            # Validation\n",
    "            FFnmodel.eval()\n",
    "            val_preds, val_labels = [], []\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for tcr, epi, label in val_loader:\n",
    "                    tcr, epi, label = tcr.to(device), epi.to(device), label.to(device)\n",
    "                    outputs = FFnmodel(tcr, epi).squeeze()\n",
    "                    val_preds.extend(outputs.cpu().numpy())\n",
    "                    val_labels.extend(label.cpu().numpy())\n",
    "            \n",
    "            # Compute metrics\n",
    "            val_preds_binary = [1 if p >= 0.5 else 0 for p in val_preds]\n",
    "            \n",
    "            fold_acc = accuracy_score(val_labels, val_preds_binary)\n",
    "            fold_prec = precision_score(val_labels, val_preds_binary)\n",
    "            fold_rec = recall_score(val_labels, val_preds_binary)\n",
    "            fold_auc = roc_auc_score(val_labels, val_preds)\n",
    "            \n",
    "            fold_metrics['accuracies'].append(fold_acc)\n",
    "            fold_metrics['precisions'].append(fold_prec)\n",
    "            fold_metrics['recalls'].append(fold_rec)\n",
    "            fold_metrics['aucs'].append(fold_auc)\n",
    "        \n",
    "        # Compute average metrics for this hyperparameter set\n",
    "        avg_metrics = {k: np.mean(v) for k, v in fold_metrics.items()}\n",
    "        avg_metrics['params'] = params\n",
    "        all_results.append(avg_metrics)\n",
    "        \n",
    "        # Update best parameters\n",
    "        if avg_metrics['aucs'] > best_avg_auc:\n",
    "            best_avg_auc = avg_metrics['aucs']\n",
    "            best_params = params\n",
    "        \n",
    "        print(\"\\nAverage Metrics:\")\n",
    "        for metric, value in avg_metrics.items():\n",
    "            if metric != 'params':\n",
    "                print(f\"{metric.capitalize()}: {value:.4f}\")\n",
    "    \n",
    "    # Sort results by AUC\n",
    "    all_results.sort(key=lambda x: x['aucs'], reverse=True)\n",
    "    \n",
    "    print(\"\\nTop 3 Hyperparameter Configurations:\")\n",
    "    for result in all_results[:3]:\n",
    "        print(\"\\nParameters:\")\n",
    "        for k, v in result['params'].items():\n",
    "            print(f\"{k}: {v}\")\n",
    "        print(\"Metrics:\")\n",
    "        for metric, value in result.items():\n",
    "            if metric not in ['params', 'aucs']:\n",
    "                print(f\"{metric.capitalize()}: {value:.4f}\")\n",
    "        print(f\"AUC: {result['aucs']:.4f}\")\n",
    "    \n",
    "    print(\"\\nBest Hyperparameters:\")\n",
    "    for k, v in best_params.items():\n",
    "        print(f\"{k}: {v}\")\n",
    "    \n",
    "    return {\n",
    "        'best_params': best_params,\n",
    "        'all_results': all_results\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = hyperparameter_tuning(dat, CombinedModel, device)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6269395,
     "sourceId": 10154626,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6269805,
     "sourceId": 10155208,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6296017,
     "sourceId": 10190390,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6296753,
     "sourceId": 10191365,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6298681,
     "sourceId": 10193955,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30805,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
