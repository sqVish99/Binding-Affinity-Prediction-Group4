{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"DATA LOADER","metadata":{}},{"cell_type":"code","source":"import re\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom typing import List, Tuple\n\n# Tokenizer\ndef tokenizer(sequence: str) -> List[str]:\n    sequence = re.sub(r'\\s+', '', str(sequence))\n    sequence = re.sub(r'[^ARNDCQEGHILKMFPSTWYVBZX]', '*', sequence)\n    return list(sequence)\n\n# Vocabulary mappings\nAMINO_MAP = {\n    '<pad>': 24, '*': 23, 'A': 0, 'C': 4, 'B': 20,\n    'E': 6, 'D': 3, 'G': 7, 'F': 13, 'I': 9, 'H': 8,\n    'K': 11, 'M': 12, 'L': 10, 'N': 2, 'Q': 5, 'P': 14,\n    'S': 15, 'R': 1, 'T': 16, 'W': 17, 'V': 19, 'Y': 18,\n    'X': 22, 'Z': 21\n}\n\nAMINO_MAP_REV = [\n    'A', 'R', 'N', 'D', 'C', 'Q', 'E', 'G', 'H', 'I', 'L', 'K',\n    'M', 'F', 'P', 'S', 'T', 'W', 'Y', 'V', 'B', 'Z', 'X', '*', '@'\n]\n\nAMINO_MAP_REV_ = ['A','R','N','D','C','Q','E','G','H','I','L','K',\n                 'M','F','P','S','T','W','Y','V','N','Q','*','*','@']\n\n# Padding function\ndef pad_sequence(sequence: List[int], max_length: int, pad_type: str = \"end\") -> List[int]:\n    pad_token = AMINO_MAP['<pad>']\n    if len(sequence) > max_length:\n        return sequence[:max_length]\n    padding = [pad_token] * (max_length - len(sequence))\n    if pad_type == \"front\":\n        return padding + sequence\n    elif pad_type == \"mid\":\n        half = len(padding) // 2\n        return padding[:half] + sequence + padding[half:]\n    else:  # Default is \"end\"\n        return sequence + padding\n\n# Dataset class\nclass CustomDataset(Dataset):\n    def __init__(self, peptides: List[str], tcrs: List[str], labels: List[float] = None, \n                 maxlen_pep: int = 15, maxlen_tcr: int = 25, pad_type: str = \"end\"):\n        self.peptides = [self.encode_sequence(tokenizer(pep), maxlen_pep, pad_type) for pep in peptides]\n        self.tcrs = [self.encode_sequence(tokenizer(tcr), maxlen_tcr, pad_type) for tcr in tcrs]\n        self.labels = labels if labels is not None else [0.0] * len(peptides)\n        self.maxlen_pep = maxlen_pep\n        self.maxlen_tcr = maxlen_tcr\n\n    def __len__(self):\n        return len(self.peptides)\n\n    def __getitem__(self, idx):\n        return {\n            \"peptides\": torch.tensor(self.peptides[idx], dtype=torch.long),\n            \"tcrs\": torch.tensor(self.tcrs[idx], dtype=torch.long),\n            \"labels\": torch.tensor(self.labels[idx], dtype=torch.float32)\n        }\n\n    @staticmethod\n    def encode_sequence(sequence: List[str], max_length: int, pad_type: str) -> List[int]:\n        token_ids = [AMINO_MAP.get(token, AMINO_MAP['*']) for token in sequence]\n        return pad_sequence(token_ids, max_length, pad_type)\n\n# Collate function for DataLoader\ndef collate_fn(batch: List[dict]) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    peptides = torch.stack([item[\"peptides\"] for item in batch])\n    tcrs = torch.stack([item[\"tcrs\"] for item in batch])\n    labels = torch.stack([item[\"labels\"] for item in batch])\n    return peptides, tcrs, labels\n\n# DataLoader utility\ndef create_dataloader(peptides: List[str], tcrs: List[str], labels: List[float] = None, \n                      batch_size: int = 32, shuffle: bool = True, \n                      maxlen_pep: int = 15, maxlen_tcr: int = 25, pad_type: str = \"end\"):\n    dataset = CustomDataset(peptides, tcrs, labels, maxlen_pep, maxlen_tcr, pad_type)\n    return DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, collate_fn=collate_fn)\n\ndef load_embedding(filename):\n    '''\n    read in BLOSUM matrix\n\n    parameters:\n        - filename : file containing BLOSUM matrix\n\n    returns:\n        - blosum embedding matrix: list\n    '''\n    if filename is None or filename.lower() == 'none':\n        filename = '/kaggle/input/blosum/BLOSUM62.txt'\n    \n    embedding_file = open(filename, \"r\")\n    lines = embedding_file.readlines()[7:]\n    embedding_file.close()\n\n    embedding = [[float(x) for x in l.strip().split()[1:]] for l in lines]\n    embedding.append([0.0] * len(embedding[0]))\n\n    return embedding\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"UTILS","metadata":{}},{"cell_type":"code","source":"import os\nimport re\nimport sys\nimport time\nimport math\nimport torch\nimport argparse\nimport numpy as np\nfrom pathlib import Path\nimport torch.nn.functional as F\nfrom tensorboardX import SummaryWriter\nfrom sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score, confusion_matrix\n# from data_loader import AMINO_MAP, AMINO_MAP_REV, AMINO_MAP_REV_\nfrom collections import defaultdict\n\nBASICITY = {'A': 206.4, 'B': 210.7, 'C': 206.2, 'D': 208.6, 'E': 215.6, 'F': 212.1, 'G': 202.7,\n            'H': 223.7, 'I': 210.8, 'K': 221.8, 'L': 209.6, 'M': 213.3, 'N': 212.8, 'P': 214.4,\n            'Q': 214.2, 'R': 237.0, 'S': 207.6, 'T': 211.7, 'V': 208.7, 'W': 216.1, 'X': 210.2,\n            'Y': 213.1, 'Z': 214.9, '*': 213.1, '@': 0}\n\nHYDROPHOBICITY = {'A': 0.16, 'B': -3.14, 'C': 2.50, 'D': -2.49, 'E': -1.50, 'F': 5.00, 'G': -3.31,\n                  'H': -4.63, 'I': 4.41, 'K': -5.00, 'L': 4.76, 'M': 3.23, 'N': -3.79, 'P': -4.92,\n                  'Q': -2.76, 'R': -2.77, 'S': -2.85, 'T': -1.08, 'V': 3.02, 'W': 4.88, 'X': 4.59,\n                  'Y': 2.00, 'Z': -2.13, '*': -0.25, '@': 0}\n\nHELICITY = {'A': 1.24, 'B': 0.92, 'C': 0.79, 'D': 0.89, 'E': 0.85, 'F': 1.26, 'G': 1.15, 'H': 0.97,\n            'I': 1.29, 'K': 0.88, 'L': 1.28, 'M': 1.22, 'N': 0.94, 'P': 0.57, 'Q': 0.96, 'R': 0.95,\n            'S': 1.00, 'T': 1.09, 'V': 1.27, 'W': 1.07, 'X': 1.29, 'Y': 1.11, 'Z': 0.91, '*': 1.04, '@': 0}\n\nMUTATION_STABILITY = {'A': 13.0, 'B': 8.5, 'C': 52.0, 'D': 11.0, 'E': 12.0, 'F': 32.0, 'G': 27.0, 'H': 15.0,\n                      'I': 10.0, 'K': 24.0, 'L': 34.0, 'M':  6.0, 'N':  6.0, 'P': 20.0, 'Q': 10.0, 'R': 17.0,\n                      'S': 10.0, 'T': 11.0, 'V': 17.0, 'W': 55.0, 'X': 20.65, 'Y': 31.0, 'Z': 11.0, '*': 20.65, '@': 0}\n\n\ndef cuda(tensor, is_cuda):\n\n    if is_cuda:\n        return tensor.cuda()\n    else:\n        return tensor\n\n\ndef idxtobool(idx, size, is_cuda):\n\n    V = cuda(torch.zeros(size, dtype=torch.float), is_cuda)\n    if len(size) > 2:\n\n        for i in range(size[0]):\n            for j in range(size[1]):\n                subidx = idx[i, j, :]\n                V[i, j, subidx] = float(1)\n    elif len(size) == 2:\n\n        for i in range(size[0]):\n            subidx = idx[i, :]\n            V[i, subidx] = float(1)\n\n    else:\n        raise argparse.ArgumentTypeError('len(size) should be larger than 1')\n\n    return V\n\n\ndef create_tensorboard(tensorboard_name):\n\n    tbf = None\n    summary_dir = Path('tensorboards').joinpath(tensorboard_name)\n    if not summary_dir.exists():\n        summary_dir.mkdir(parents=True)\n    tbf = SummaryWriter(log_dir=str(summary_dir))\n\n    return tbf\n\n\ndef write_blackbox_output_batchiter(loader, model, wf, device='cpu', ifscore=True):\n\n    model.eval()\n\n    rev_peploader = loader['pep_amino_idx']\n    rev_tcrloader = loader['tcr_amino_idx']\n    loader = loader['loader']\n    for batch in loader:\n\n        X_pep, X_tcr, y = batch.X_pep.to(\n            device), batch.X_tcr.to(device), batch.y.to(device)\n        score = model(X_pep, X_tcr).data.cpu().tolist()\n        score = [s[0] for s in score]\n        pred = [round(s) for s in score]\n\n        for i in range(len(pred)):\n\n            pep_seq = ''.join([rev_peploader[x] for x in X_pep[i]])\n            pep_seq = re.sub(r'<pad>', '', pep_seq)\n            pep_seq = re.sub(r'@', '', pep_seq)\n            tcr_seq = ''.join([rev_tcrloader[x] for x in X_tcr[i]])\n            tcr_seq = re.sub(r'<pad>', '', tcr_seq)\n            tcr_seq = re.sub(r'@', '', tcr_seq)\n            if ifscore:\n                wf.writerow([pep_seq, tcr_seq, int(y[i]),\n                             int(pred[i]), float(score[i])])\n            else:\n                wf.writerow([pep_seq, tcr_seq, int(pred[i])])\n\ndef get_label_batchiter(loader, model, device='cpu'):\n    '''\n    print classification performance for binary task\n\n    Args:\n     loader  - data loader\n     model   - classification model\n     loss_ft - loss function\n    '''\n    model.eval()\n\n    loss = 0\n    predicted_labels = []\n    for batch in loader:\n\n        X_pep, X_tcr, _ = batch\n        X_pep = X_pep.to(device)\n        X_tcr = X_tcr.to(device)\n    \n        yhat = model(X_pep, X_tcr)\n        predicted_labels.extend((yhat.data.cpu() > 0.5).int().tolist())  # Apply threshold to get predictions\n\n    return predicted_labels\n\ndef get_label_prob_batchiter(loader, model, device='cpu'):\n    '''\n    print classification performance for binary task\n\n    Args:\n     loader  - data loader\n     model   - classification model\n     loss_ft - loss function\n    '''\n    model.eval()\n\n    loss = 0\n    predicted_labels = []\n    for batch in loader:\n\n        X_pep, X_tcr, _ = batch\n        X_pep = X_pep.to(device)\n        X_tcr = X_tcr.to(device)\n    \n        yhat = model(X_pep, X_tcr)\n        predicted_labels.extend(yhat.data.cpu().tolist())  \n\n    return predicted_labels\ndef get_performance_batchiter(loader, model, device='cpu'):\n    '''\n    print classification performance for binary task\n\n    Args:\n     loader  - data loader\n     model   - classification model\n     loss_ft - loss function\n    '''\n    model.eval()\n\n    loss = 0\n    score, label = [], []\n    for batch in loader:\n\n        X_pep, X_tcr, y = batch\n        X_pep = X_pep.to(device)\n        X_tcr = X_tcr.to(device)\n        y = y.to(device)\n        yhat = model(X_pep, X_tcr)\n        y = y.unsqueeze(-1).expand_as(yhat)\n        loss += F.binary_cross_entropy(yhat, y, reduction='sum').item()\n        score.extend(yhat.data.cpu().tolist())\n        label.extend(y.data.cpu().tolist())\n\n\n    perf = get_performance(score, label)\n    perf['loss'] = round(loss, 4)\n\n    return perf\n\n\ndef get_performance(score, label):\n    '''\n    get classification performance for binary task\n\n    Args:\n     score - 1D np.array or list\n     label - 1D np.array or list\n    '''\n\n    accuracy = None\n    precision1, precision0 = None, None\n    recall1, recall0 = None, None\n    f1macro, f1micro = None, None\n    auc = None\n\n    # if type(score) is list():\n    #    score = np.array(score)\n    # if type(label) is list():\n    #    label = np.array(label)\n\n    label_pred = [round(s[0]) for s in score]\n    accuracy = accuracy_score(label, label_pred)\n    precision1 = precision_score(\n        label, label_pred, pos_label=1, zero_division=0)\n    precision0 = precision_score(\n        label, label_pred, pos_label=0, zero_division=0)\n    recall1 = recall_score(label, label_pred, pos_label=1, zero_division=0)\n    recall0 = recall_score(label, label_pred, pos_label=0, zero_division=0)\n    f1macro = f1_score(label, label_pred, average='macro')\n    f1micro = f1_score(label, label_pred, average='micro')\n    auc = roc_auc_score(np.array(label), np.array(score)) if len(\n        np.unique(np.array(label))) != 1 else -1\n\n    ndigits = 4\n    performance = {'accuracy': round(accuracy, ndigits),\n                   'precision1': round(precision1, ndigits), 'precision0': round(precision0, ndigits),\n                   'recall1': round(recall1, ndigits), 'recall0': round(recall0, ndigits),\n                   'f1macro': round(f1macro, ndigits), 'f1micro': round(f1micro, ndigits),\n                   'auc': round(auc, ndigits)}\n    tn, fp, fn, tp = confusion_matrix(label, label_pred, labels=[0, 1]).ravel()\n    print(tn, fp, fn, tp)\n    return performance\n\n\ndef print_performance(perf, printif=True, writeif=False, boardif=False, **kargs):\n    '''\n    print classification performance for binary task\n\n    Args:\n     per   - dictionary with measure name as keys and performance as values \n             or perf = get_performance(score, label)\n     kargs - epoch, loss, global_step\n             wf = open(outfile_name, 'w')\n             tbf = create_tensorboard(tensorboard_name)\n    '''\n\n    measures = sorted(perf.keys())\n\n    if printif:\n        maxchrlen = max([len(x) for x in measures])\n        for mea in measures:\n            print(mea + ' ' * (maxchrlen - len(mea)) +\n                  ' {:.4f}'.format(perf[mea]))\n        print('')\n\n    if boardif:\n        assert 'tbf' in kargs.keys(), 'missing argument: tbf'\n        assert 'global_step' in kargs.keys(), 'missing argument: global_step'\n        assert 'mode' in kargs.keys(), 'missing argument: mode'\n        for mea in measures:\n            kargs['tbf'].add_scalars(main_tag='performance/{}'.format(mea),\n                                     tag_scalar_dict={\n                                         kargs['mode']: perf[mea]},\n                                     global_step=kargs['global_step'])\n\n    if writeif:\n        assert 'wf' in kargs.keys(), 'missing argument: wf'\n        #newrow = [perf[x] for x in measures]\n        # kargs['wf'].writerow(newrow)\n        kargs['wf'].writerow(perf)\n        return kargs['wf']\n\n\ndef str2bool(v):\n    \"\"\"\n    Convert string to boolean object\n\n    \"\"\"\n\n    if v.lower() in ('yes', 'true', 't', 'y', '1', 'True', 'Y', 'Yes', 'YES', 'YEs', 'ye'):\n        return True\n    elif v.lower() in ('no', 'false', 'f', 'n', '0', 'False', 'N', 'NO', 'No'):\n        return False\n    else:\n        raise argparse.ArgumentTypeError('Boolean value expected.')\n\n\ndef timeSince(since):\n    \"\"\"\n    Credit: https://github.com/1Konny/VIB-pytorch\n    \"\"\"\n    now = time.time()\n    s = now - since\n    m = math.floor(s / 60)\n    s -= m * 60\n\n    return '%dm %ds' % (m, s)\n\n\ndef check_model_name(model_name, file_path='models'):\n    \"\"\"\n    Check whether model name is overlapped or not \n    \"\"\"\n    if model_name in os.listdir(file_path):\n\n        valid = {\"yes\": True, \"y\": True, \"ye\": True, 'true': True, 't': True,\n                 '1': True, \"no\": False, \"n\": False, 'false': False, 'f': False, '0': False}\n        sys.stdout.write(\n            \"The file {} already exists. Do you want to overwrite it? [yes/no]\".format(model_name))\n        choice = input().lower()\n\n        if choice in valid:\n            if not valid[choice]:\n                sys.stdout.write(\n                    \"Please assign another name. (ex. 'original_2.ckpt')\")\n                model_name = input().lower()\n                check_model_name(model_name=model_name, file_path=file_path)\n\n        else:\n            sys.stdout.write(\"Please respond with 'yes' or 'no'\\n\")\n            check_model_name(model_name=model_name, file_path=file_path)\n\n    return model_name\n\n\ndef get_physchem_properties_batchiter(loader, lenpep, lentcr, device='cpu'):\n    '''\n    print physiochemical properties \n\n    Args:\n     loader  - data loader\n     args   - arguments\n    '''\n\n    global features\n    features = None\n\n    for batch in loader:\n\n        # Input\n        X_pep, X_tcr, y_true = batch.X_pep.to(\n            device), batch.X_tcr.to(device), batch.y.to(device)\n\n        get_physchem_properties(X_pep[np.where(y_true == 1.0)].tolist(),\n                                X_tcr[np.where(y_true == 1.0)].tolist(),\n                                lenpep, lentcr,\n                                exclude=set(['X', '*']))\n\n    return features\n\n\ndef get_physchem_properties(pep_batch, tcr_batch,\n                            max_len_pep, max_len_tcr, exclude):\n\n    global features\n\n    pep_batch = num2seq(pep_batch, AMINO_MAP_REV_, max_len=max_len_pep,\n                        align=False, exclude=exclude)\n    tcr_batch = num2seq(tcr_batch, AMINO_MAP_REV, max_len=max_len_tcr,\n                        align=False, exclude=exclude)\n\n    if not features:\n        features = defaultdict(lambda: defaultdict(list))\n\n    for pep, tcr in zip(pep_batch, tcr_batch):\n        features[pep]['tcr'].append(tcr)\n        features[pep]['basicity'].append([BASICITY[aa] for aa in tcr])\n        features[pep]['hydrophobicity'].append(\n            [HYDROPHOBICITY[aa] for aa in tcr])\n        features[pep]['helicity'].append([HELICITY[aa] for aa in tcr])\n        features[pep]['mutation_stability'].append(\n            [MUTATION_STABILITY[aa] for aa in tcr])\n\n        # features[pep]['length'].append(len(tcr))\n        # features[pep]['fast_mass'].append(mass.fast_mass(tcr))\n        # features[pep]['pI'].append(electrochem.pI(tcr))\n        #ac_comp = parser.amino_acid_composition(tcr)\n        # for aa in AMINO_MAP_REV[:-2]:\n        #    features[pep][aa].append(ac_comp[aa])\n\n\ndef print_physchem_properties(perf, wf, measures=None):\n\n    if measures is None:\n        measures = sorted(perf.keys())\n\n    wf.writerow(measures)\n    for i in range(len(perf[measures[0]])):\n        wf.writerow([perf[mea][i] for mea in measures])\n\n\ndef seq2num(seq_list, mapping, max_len=None, align=True):\n\n    num_list = []\n\n    if align:\n\n        for seq in seq_list:\n\n            if max_len is None:\n                num = [mapping[seq[i]] for i in range(len(num))]\n            elif max_len > len(seq):\n                num = [mapping[seq[i]] for i in range(\n                    len(seq))] + [mapping['<pad>'] for _ in range(max_len - len(seq))]\n            else:\n                num = [mapping[seq[i]] for i in range(max_len)]\n\n            num_list.append(num)\n\n    else:\n\n        for seq in seq_list:\n\n            if max_len is None or max_len > len(seq):\n                num = [mapping[seq[i]]\n                       for i in range(len(num)) if seq[i] != '<pad>']\n            else:\n                num = [mapping[seq[i]]\n                       for i in range(len(seq)) if seq[i] != '<pad>']\n\n            num_list.append(num)\n\n    return num_list\n\n\ndef num2seq(num_list, mapping, max_len=None, align=True, exclude=set(['@'])):\n\n    seq_list = []\n\n    if align:\n\n        for num in num_list:\n\n            if max_len is None:\n                seq = [mapping[num[i]] for i in range(len(num))]\n            elif max_len > len(num):\n                seq = [mapping[num[i]] for i in range(len(num))]\n            else:\n                seq = [mapping[num[i]] for i in range(max_len)]\n\n            seq_list.append(''.join(seq))\n\n    else:\n\n        for num in num_list:\n\n            if max_len is None or max_len > len(num):\n                seq = [mapping[num[i]]\n                       for i in range(len(num)) if mapping[num[i]] not in exclude]\n            else:\n                seq = [mapping[num[i]]\n                       for i in range(max_len) if mapping[num[i]] not in exclude]\n\n            seq_list.append(''.join(seq))\n\n    return seq_list","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"MODEL","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\n\nclass Net(nn.Module):\n    def __init__(self, embedding,dim_hidden1, dim_hidden2, dropout1, dropout2):\n        super(Net, self).__init__()\n\n        # Embedding Layer\n        self.num_amino = len(embedding)\n        self.embedding_dim = len(embedding[0])\n        self.embedding = nn.Embedding(self.num_amino, self.embedding_dim, padding_idx=self.num_amino - 1)\n        self.embedding = self.embedding.from_pretrained(torch.FloatTensor(embedding), freeze=False)\n\n        # Self-Attention Layers\n        self.attn_tcr = nn.MultiheadAttention(embed_dim=self.embedding_dim, num_heads=4)\n        self.attn_pep = nn.MultiheadAttention(embed_dim=self.embedding_dim, num_heads=4)\n\n        # Dense Layers\n        self.size_hidden1_dense = dim_hidden1\n        self.size_hidden2_dense = dim_hidden2\n        self.net_pep_dim = 22 * self.embedding_dim\n        self.net_tcr_dim = 20 * self.embedding_dim\n        self.net = nn.Sequential(\n            nn.Linear(self.net_pep_dim + self.net_tcr_dim,\n                      self.size_hidden1_dense),\n            nn.BatchNorm1d(self.size_hidden1_dense),\n            nn.Dropout(dropout1),\n            nn.SiLU(),\n            nn.Linear(self.size_hidden1_dense, self.size_hidden2_dense),\n            nn.BatchNorm1d(self.size_hidden2_dense),\n            nn.Dropout(dropout2),\n            nn.SiLU(),\n            nn.Linear(self.size_hidden2_dense, 1),\n            nn.Sigmoid()\n        )\n\n    def forward(self, pep, tcr):\n        # Embedding\n        pep = self.embedding(pep)  # batch * len * dim\n        tcr = self.embedding(tcr)  # batch * len * dim\n\n        # Transpose (seq_len, batch, embed_dim)\n        pep = torch.transpose(pep, 0, 1)\n        tcr = torch.transpose(tcr, 0, 1)\n\n        # Self-Attention\n        pep, _ = self.attn_pep(pep, pep, pep)\n        tcr, _ = self.attn_tcr(tcr, tcr, tcr)\n\n        # Transpose back (batch, seq_len, embed_dim)\n        pep = torch.transpose(pep, 0, 1)\n        tcr = torch.transpose(tcr, 0, 1)\n\n        # Linear Layers\n        pep = pep.reshape(-1, 1, pep.size(-2) * pep.size(-1))\n        tcr = tcr.reshape(-1, 1, tcr.size(-2) * tcr.size(-1))\n        peptcr = torch.cat((pep, tcr), -1).squeeze(-2)\n        peptcr = self.net(peptcr)\n\n        return peptcr\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def train(model, device, train_loader, optimizer, epoch):\n\n    model.train()\n\n    for batch in train_loader:\n\n        # x_pep, x_tcr, y = batch.X_pep.to(\n        #     device), batch.X_tcr.to(device), batch.y.to(device)\n        X_pep, X_tcr, y = batch\n        X_pep = X_pep.to(device)\n        X_tcr = X_tcr.to(device)\n        y = y.to(device)\n\n        optimizer.zero_grad()\n        yhat = model(X_pep, X_tcr)\n        y = y.unsqueeze(-1).expand_as(yhat)\n        loss = F.binary_cross_entropy(yhat, y)\n        loss.backward()\n        optimizer.step()\n\n    # if epoch % 2 == 1:\n    #     print('[TRAIN] Epoch {} Loss {:.4f}'.format(epoch, loss.item()))\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nembedding_matrix = load_embedding(None)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch.optim as optim\n\ntorch.manual_seed(42)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\ncolumn_names = ['antigen', 'cdr3_sequence', 'class']\ndf = pd.read_csv('/kaggle/input/data-tcr/data/BAP/tcr_split/train.csv',header=None, names=column_names)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Hyper-Parameter Tuning with 5 fold cross validation\nimport time\nimport torch\nimport os\nimport csv\nfrom collections import deque\nfrom sklearn.model_selection import KFold, train_test_split\nfrom torch.optim import Adam, SGD\nfrom itertools import product\n\n# Initialize CSV for metrics\nfile_name = 'ATMTCR_tcr_base_model_metrics_final.csv'\n\n# Open the file in append mode\nwf_open = open(file_name, 'a+', newline='')\nbest_performance_data = []\n\n# Move to the beginning of the file and check if it's empty\nwf_open.seek(0)\nis_empty = len(wf_open.read().strip()) == 0\n\n# Define column names\nwf_colnames = ['fold', 'epoch', 'loss', 'accuracy', 'precision1', 'precision0',\n               'recall1', 'recall0', 'f1macro', 'f1micro', 'auc']\n\n# Initialize DictWriter\nwf = csv.DictWriter(wf_open, fieldnames=wf_colnames, delimiter='\\t')\n\n# Write the header only if the file is empty\nif is_empty:\n    wf.writeheader()\n\n# Hyperparameter search space\n\n\nhyperparameter_space = {\n    'padding': ['front', 'mid','end'],\n    'dropout1': [0.5, 0.6],\n    'dropout2': [0.25, 0.3, 0.5],\n    'maxlen_tcr': [10, 15, 18, 20, 22],\n    'maxlen_pep': [10, 15, 18, 20, 22],\n    'dim_hidden1': [256, 512, 1024, 2048, 4096],\n    'dim_hidden2': [256, 512, 1024, 2048]\n}\nbest_hyperparameters={}\n# Prepare data\npepts = df['antigen'].tolist()\ntcrs = df['cdr3_sequence'].tolist()\nlabels = df['class'].tolist()\n\nkf = KFold(n_splits=5, shuffle=True, random_state=42)\n\nt0 = time.time()\n\nbest_loss = float('inf')\nbest_params = None\nbest_model = None\n\nparam_combinations = list(product(*hyperparameter_space.values()))\nkfold = KFold(n_splits=5, shuffle=True, random_state=42)\n\nfor params in param_combinations:\n    param_dict = dict(zip(hyperparameter_space.keys(), params))\n    print(f\"Testing parameters: {param_dict}\")\n    padding, dropout_dense1, dropout_dense2, maxlen_tcr, maxlen_pep, dense1_dim, dense2_dim = params\n\n    fold = 1\n    # Cross-validation\n    for train_indices, test_indices in kf.split(pepts):\n        print(f\"\\nStarting fold {fold}...\")\n\n        # Create initial training and testing splits\n        X_train_pep = [pepts[i] for i in train_indices]\n        X_train_tcr = [tcrs[i] for i in train_indices]\n        y_train = [labels[i] for i in train_indices]\n\n        X_test_pep = [pepts[i] for i in test_indices]\n        X_test_tcr = [tcrs[i] for i in test_indices]\n        y_test = [labels[i] for i in test_indices]\n\n        # Create DataLoaders (no validation set)\n        Train_Loader = create_dataloader(X_train_pep, X_train_tcr, y_train,\n                                                 batch_size=32, shuffle=True, maxlen_pep=maxlen_pep, maxlen_tcr=maxlen_tcr, pad_type=padding)\n\n        Test_Loader = create_dataloader(X_test_pep, X_test_tcr, y_test,\n                                                batch_size=32, shuffle=False, maxlen_pep=maxlen_pep, maxlen_tcr=maxlen_tcr, pad_type=padding)\n\n        # Initialize model, optimizer, and other components for each fold\n        lossArraySize = 10\n        lossArray = deque([sys.maxsize], maxlen=lossArraySize)\n               \n        best_perf_test = None  # To store the best test performance\n\n        for epoch in range(1, 201):  \n            epoch_loss = 0\n            model = Net(embedding=embedding_matrix,dim_hidden1=dense1_dim, dim_hidden2=dense2_dim,dropout1=dropout_dense1, dropout2=dropout_dense2).to(device)\n            optimizer = torch.optim.Adam(model.parameters(), lr=0.001, betas=(0.5, 0.999), eps=1e-8)\n\n            # Train the model\n            train(model, device, Train_Loader, optimizer, epoch)\n\n            # Evaluate the model on the test set\n            perf_test = get_performance_batchiter(Test_Loader, model, device)\n            print(f\"[TEST - Fold {fold}] Epoch {epoch} ----------------\")\n            print_performance(perf_test, printif=False, writeif=False)\n\n            # Check for early stopping\n            lossArray.append(perf_test['loss'])\n            average_loss_change = sum(np.abs(np.diff(lossArray))) / lossArraySize\n            if epoch > 5 and average_loss_change < 10:\n                print(f\"Early stopping at epoch {epoch} for fold {fold}\")\n                break\n\n            # Update best test performance and save it to CSV\n            if best_perf_test is None or perf_test['loss'] < best_perf_test['loss']:\n                best_perf_test = perf_test\n            # Save the best test performance for the fold\n                wf.writerow({\n                            'fold': fold,\n                            'epoch': epoch,\n                            'loss': best_perf_test['loss'],\n                            'accuracy': best_perf_test['accuracy'],\n                            'precision1': best_perf_test['precision1'],\n                            'precision0': best_perf_test['precision0'],\n                            'recall1': best_perf_test['recall1'],\n                            'recall0': best_perf_test['recall0'],\n                            'f1macro': best_perf_test['f1macro'],\n                            'f1micro': best_perf_test['f1micro'],\n                            'auc': best_perf_test['auc']\n                })\n                best_performance_data.append(best_perf_test)\n\n                print(f\"Best test performance for fold {fold} updated at epoch {epoch}\")\n\n            # Save the model checkpoint if it has the best validation loss\n            if not os.path.exists('./checkpoints'):\n                os.makedirs('./checkpoints')\n            if perf_test['loss'] < best_loss:\n                best_loss = perf_test['loss']\n                checkpoint_path = os.path.join(f\"checkpoints/ATMTCR_tcr_base.pt\")\n                torch.save({\n                            'epoch': epoch,\n                            'model_state_dict': model.state_dict(),\n                            'optimizer_state_dict': optimizer.state_dict(),\n                            'loss': perf_test['loss'],\n                    }, checkpoint_path)\n                print(f\"Checkpoint saved at {checkpoint_path}\")\n\n                # Update the best hyperparameters\n                best_hyperparameters=param_dict\n\n        print(f\"Fold {fold} completed.\")\n        fold += 1\n\n\nprint(f\"Training completed. Total time: {timeSince(t0)}\")\nwf_open.close()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Output the best hyperparameters and performance\nprint(\"\\nBest Hyperparameters and Performance:\")\nprint(best_hyperparameters)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Training Complete - Now Load Test Data\ndf = pd.read_csv('/kaggle/input/data-tcr/data/BAP/tcr_split/test.csv',header=None, names=column_names)\ntest_pepts = df['antigen'].tolist()\ntest_tcrs = df['cdr3_sequence'].tolist()\ndummy_labels = np.zeros(len(test_pepts))  # Create dummy labels for testing\nTest_Loader = create_dataloader(test_pepts, test_tcrs, dummy_labels, batch_size=32,shuffle=False,maxlen_pep=22,maxlen_tcr=20, pad_type=\"end\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def load_checkpoint(model, optimizer, checkpoint_path):\n    checkpoint = torch.load(checkpoint_path)\n    \n    # Load the model state_dict\n    model.load_state_dict(checkpoint['model_state_dict'])\n    \n    # Load the optimizer state_dict\n    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n    \n    # Get the epoch and loss\n    epoch = checkpoint['epoch']\n    loss = checkpoint['loss']\n    \n    return model, optimizer, epoch, loss","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model, optim, epoch, loss = load_checkpoint(model, optimizer, \"checkpoints/ATMTCR_tcr_base.pt\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"torch.save(model.state_dict(), 'ATMTCR_tcr_base_model_weights.pt')\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"labels = get_label_batchiter(\n        Test_Loader, model, device)\n\n# Save predictions to a CSV file\nimport pandas as pd\n\npred_df = pd.DataFrame(labels, columns=['Predicted Probability'])\npred_df.to_csv('base_tcr_test_predictions.csv', index=False)\n\nprint(\"Predictions saved to 'test_predictions.csv'\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(len(test_pepts))","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}