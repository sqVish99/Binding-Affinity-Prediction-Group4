{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-14T03:09:47.237253Z",
     "iopub.status.busy": "2024-12-14T03:09:47.236795Z",
     "iopub.status.idle": "2024-12-14T03:10:07.021224Z",
     "shell.execute_reply": "2024-12-14T03:10:07.020275Z",
     "shell.execute_reply.started": "2024-12-14T03:09:47.237214Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from transformers import TFBertModel,BertModel, BertForPreTraining, BertTokenizer, BertConfig\n",
    "import torch\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"/kaggle/input/catelmo-bert-tiny/\", do_lower_case=False )\n",
    "model = BertModel.from_pretrained(\"/kaggle/input/catelmo-bert-tiny/\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "def pad_sequence(sequence, tokenizer, max_length=44):\n",
    "    seq = \" \".join(sequence)\n",
    "    # Padding/truncation using the tokenizer\n",
    "    tokens = tokenizer(seq, padding='max_length', truncation=True, max_length=max_length, return_tensors='pt')\n",
    "    return tokens['input_ids'].squeeze(0)\n",
    "\n",
    "def BERT_embedding(x, TOKENIZER, DEVICE, max_length=44, spad=True):\n",
    "    if spad:\n",
    "        padded_input = pad_sequence(x, tokenizer, max_length)\n",
    "        encoded_input = padded_input.unsqueeze(0).to(device)  # Add batch dimension\n",
    "    else:\n",
    "        seq = \" \".join(x)\n",
    "        seq = re.sub(r\"[UZOB]\", \"X\", seq)\n",
    "        encoded_input = tokenizer(seq, return_tensors='pt').to(device)\n",
    "    if spad:\n",
    "        output = model(encoded_input) \n",
    "    else:\n",
    "        output = model(**encoded_input)\n",
    "    return output\n",
    "\n",
    "column_names = ['antigen', 'cdr3_sequence', 'class']\n",
    "dat = pd.read_csv('/kaggle/input/tcrdata/data/BAP/tcr_split/train.csv',header=None, names=column_names)\n",
    "dat['tcr_embeds'] = None\n",
    "dat['epi_embeds'] = None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T22:19:36.329062Z",
     "iopub.status.busy": "2024-12-13T22:19:36.328061Z",
     "iopub.status.idle": "2024-12-13T22:34:56.808013Z",
     "shell.execute_reply": "2024-12-13T22:34:56.807003Z",
     "shell.execute_reply.started": "2024-12-13T22:19:36.329023Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for i in tqdm(range(len(dat))):\n",
    "    # Generating embeddings using the BERT embedding function\n",
    "    epi_embed = BERT_embedding(dat.antigen[i], tokenizer, device,16, False)[0].reshape(-1,768).mean(dim=0).tolist()  # Assume shape (N, D) or (D,)\n",
    "    tcr_embed = BERT_embedding(dat.cdr3_sequence[i], tokenizer, device, 16, False)[0].reshape(-1,768).mean(dim=0).tolist()  # Assume shape (N, D) or (D,)\n",
    "\n",
    "    # Saving embeddings as lists in the DataFrame\n",
    "    dat.at[i, 'epi_embeds'] = epi_embed  # Use .at for row assignment\n",
    "    dat.at[i, 'tcr_embeds'] = tcr_embed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-14T03:10:39.170663Z",
     "iopub.status.busy": "2024-12-14T03:10:39.170304Z",
     "iopub.status.idle": "2024-12-14T03:10:57.868964Z",
     "shell.execute_reply": "2024-12-14T03:10:57.868237Z",
     "shell.execute_reply.started": "2024-12-14T03:10:39.170634Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# optional: To save/load files\n",
    "# dat.to_pickle('/kaggle/input/bert-embeddings-catelmo/epi_train_tiny_embeddings_768.pkl')\n",
    "# dat.to_pickle('/kaggle/input/bert-embeddings-catelmo/epi_train_tiny_embeddings_768.pkl')\n",
    "# dat = pd.read_pickle('/kaggle/input/bert-embeddings-catelmo/epi_train_tiny_embeddings_768.pkl')\n",
    "# dat2 = pd.read_pickle('/kaggle/input/bert-embeddings-catelmo/epi_test_tiny_embeddings_768.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-14T03:10:57.870160Z",
     "iopub.status.busy": "2024-12-14T03:10:57.869929Z",
     "iopub.status.idle": "2024-12-14T03:10:57.888431Z",
     "shell.execute_reply": "2024-12-14T03:10:57.887570Z",
     "shell.execute_reply.started": "2024-12-14T03:10:57.870137Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "tcr_embeds = dat['tcr_embeds'].tolist()\n",
    "epi_embeds = dat['epi_embeds'].tolist()\n",
    "labels = dat['class'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-14T03:00:12.911220Z",
     "iopub.status.busy": "2024-12-14T03:00:12.910821Z",
     "iopub.status.idle": "2024-12-14T03:00:12.921423Z",
     "shell.execute_reply": "2024-12-14T03:00:12.920184Z",
     "shell.execute_reply.started": "2024-12-14T03:00:12.911186Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_dataset = TCRDataset(dat['tcr_embeds'].tolist(),\n",
    "                          dat['epi_embeds'].tolist(),\n",
    "                          dat['class'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-14T03:00:16.400781Z",
     "iopub.status.busy": "2024-12-14T03:00:16.400385Z",
     "iopub.status.idle": "2024-12-14T03:00:16.409228Z",
     "shell.execute_reply": "2024-12-14T03:00:16.408055Z",
     "shell.execute_reply.started": "2024-12-14T03:00:16.400746Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_dataset = TCRDataset(tcr_embeds = dat2['tcr_embeds'].tolist(),\n",
    "                            epi_embeds = dat2['epi_embeds'].tolist(),\n",
    "                            labels = dat2['class'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-14T03:11:18.731975Z",
     "iopub.status.busy": "2024-12-14T03:11:18.731163Z",
     "iopub.status.idle": "2024-12-14T03:11:18.744574Z",
     "shell.execute_reply": "2024-12-14T03:11:18.743740Z",
     "shell.execute_reply.started": "2024-12-14T03:11:18.731940Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from typing import List, Tuple\n",
    "\n",
    "# Tokenizer\n",
    "def tokenizer(sequence: str) -> List[str]:\n",
    "    sequence = re.sub(r'\\s+', '', str(sequence))\n",
    "    sequence = re.sub(r'[^ARNDCQEGHILKMFPSTWYVBZX]', '*', sequence)\n",
    "    return list(sequence)\n",
    "\n",
    "# Vocabulary mappings\n",
    "AMINO_MAP = {\n",
    "    '<pad>': 24, '*': 23, 'A': 0, 'C': 4, 'B': 20,\n",
    "    'E': 6, 'D': 3, 'G': 7, 'F': 13, 'I': 9, 'H': 8,\n",
    "    'K': 11, 'M': 12, 'L': 10, 'N': 2, 'Q': 5, 'P': 14,\n",
    "    'S': 15, 'R': 1, 'T': 16, 'W': 17, 'V': 19, 'Y': 18,\n",
    "    'X': 22, 'Z': 21\n",
    "}\n",
    "\n",
    "AMINO_MAP_REV = [\n",
    "    'A', 'R', 'N', 'D', 'C', 'Q', 'E', 'G', 'H', 'I', 'L', 'K',\n",
    "    'M', 'F', 'P', 'S', 'T', 'W', 'Y', 'V', 'B', 'Z', 'X', '*', '@'\n",
    "]\n",
    "\n",
    "AMINO_MAP_REV_ = ['A','R','N','D','C','Q','E','G','H','I','L','K',\n",
    "                 'M','F','P','S','T','W','Y','V','N','Q','*','*','@']\n",
    "\n",
    "# Padding function\n",
    "def pad_sequence(sequence: List[int], max_length: int, pad_type: str = \"end\") -> List[int]:\n",
    "    pad_token = AMINO_MAP['<pad>']\n",
    "    if len(sequence) > max_length:\n",
    "        return sequence[:max_length]\n",
    "    padding = [pad_token] * (max_length - len(sequence))\n",
    "    if pad_type == \"front\":\n",
    "        return padding + sequence\n",
    "    elif pad_type == \"mid\":\n",
    "        half = len(padding) // 2\n",
    "        return padding[:half] + sequence + padding[half:]\n",
    "    else:\n",
    "        return sequence + padding\n",
    "\n",
    "\n",
    "\n",
    "def encode_sequence(sequence: List[str], max_length: int, pad_type: str) -> List[int]:\n",
    "        token_ids = [AMINO_MAP.get(token, AMINO_MAP['*']) for token in sequence]\n",
    "        return pad_sequence(token_ids, max_length, pad_type)\n",
    "\n",
    "\n",
    "def load_embedding(filename):\n",
    "    if filename is None or filename.lower() == 'none':\n",
    "        filename = '/kaggle/input/blosum/BLOSUM62.txt'\n",
    "    \n",
    "    embedding_file = open(filename, \"r\")\n",
    "    lines = embedding_file.readlines()[7:]\n",
    "    embedding_file.close()\n",
    "\n",
    "    embedding = [[float(x) for x in l.strip().split()[1:]] for l in lines]\n",
    "    embedding.append([0.0] * len(embedding[0]))\n",
    "\n",
    "    return embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-14T03:11:21.967908Z",
     "iopub.status.busy": "2024-12-14T03:11:21.967589Z",
     "iopub.status.idle": "2024-12-14T03:11:21.985154Z",
     "shell.execute_reply": "2024-12-14T03:11:21.984249Z",
     "shell.execute_reply.started": "2024-12-14T03:11:21.967883Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "embedding = load_embedding(None)\n",
    "num_amino = len(embedding)\n",
    "embedding_dim = len(embedding[0])\n",
    "nn_embedding = nn.Embedding(num_amino, embedding_dim, padding_idx=num_amino-1)\n",
    "embedding_model = nn_embedding.from_pretrained(torch.FloatTensor(embedding), freeze=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-14T03:11:23.750873Z",
     "iopub.status.busy": "2024-12-14T03:11:23.750170Z",
     "iopub.status.idle": "2024-12-14T03:11:23.757419Z",
     "shell.execute_reply": "2024-12-14T03:11:23.756501Z",
     "shell.execute_reply.started": "2024-12-14T03:11:23.750838Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "embedding_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-14T03:11:26.238879Z",
     "iopub.status.busy": "2024-12-14T03:11:26.238187Z",
     "iopub.status.idle": "2024-12-14T03:13:09.741073Z",
     "shell.execute_reply": "2024-12-14T03:13:09.740371Z",
     "shell.execute_reply.started": "2024-12-14T03:11:26.238844Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "peptides = [encode_sequence(tokenizer(pep), 15, \"end\") for pep in dat['antigen'].tolist()]\n",
    "tcrs = [encode_sequence(tokenizer(dat['cdr3_sequence']), 25, \"end\")for tcr in dat['cdr3_sequence'].tolist()] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-14T03:14:43.598815Z",
     "iopub.status.busy": "2024-12-14T03:14:43.598418Z",
     "iopub.status.idle": "2024-12-14T03:15:26.389339Z",
     "shell.execute_reply": "2024-12-14T03:15:26.388590Z",
     "shell.execute_reply.started": "2024-12-14T03:14:43.598782Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    pep_blosum = embedding_model(torch.tensor(peptides).to(device))\n",
    "    tcr_blosum = embedding_model(torch.tensor(tcrs).to(device))\n",
    "pep_blosum = pep_blosum.tolist()\n",
    "tcr_blosum = tcr_blosum.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-14T03:14:31.644522Z",
     "iopub.status.busy": "2024-12-14T03:14:31.643678Z",
     "iopub.status.idle": "2024-12-14T03:14:31.650524Z",
     "shell.execute_reply": "2024-12-14T03:14:31.649592Z",
     "shell.execute_reply.started": "2024-12-14T03:14:31.644485Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class TCRDataset(Dataset):\n",
    "    def __init__(self, tcr_embeds, epi_embeds,pep_blosum, tcr_blosum, labels):\n",
    "        self.tcr_embeds = tcr_embeds\n",
    "        self.epi_embeds = epi_embeds\n",
    "        self.pep_blosum = pep_blosum\n",
    "        self.tcr_blosum = tcr_blosum\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.tcr_embeds[idx], dtype=torch.float32), \\\n",
    "               torch.tensor(self.epi_embeds[idx], dtype=torch.float32), \\\n",
    "               torch.tensor(self.pep_blosum[idx], dtype=torch.float32), \\\n",
    "               torch.tensor(self.tcr_blosum[idx], dtype=torch.float32), \\\n",
    "               torch.tensor(self.labels[idx], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-14T03:16:10.804075Z",
     "iopub.status.busy": "2024-12-14T03:16:10.803345Z",
     "iopub.status.idle": "2024-12-14T03:16:10.970447Z",
     "shell.execute_reply": "2024-12-14T03:16:10.969509Z",
     "shell.execute_reply.started": "2024-12-14T03:16:10.804036Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, test_df = train_test_split(dat, test_size=0.2, random_state=42)\n",
    "train_pep,test_pep = train_test_split(pep_blosum, test_size=0.2, random_state=42)\n",
    "train_tcr, test_tcr = train_test_split(tcr_blosum, test_size=0.2, random_state=42)\n",
    "\n",
    "train_dataset = TCRDataset(train_df['tcr_embeds'].tolist(),\n",
    "                           train_df['epi_embeds'].tolist(),\n",
    "                           train_pep,\n",
    "                           train_tcr,\n",
    "                           train_df['class'].tolist())\n",
    "\n",
    "test_dataset = TCRDataset(test_df['tcr_embeds'].tolist(),\n",
    "                          test_df['epi_embeds'].tolist(),\n",
    "                          test_pep,\n",
    "                          test_tcr,\n",
    "                          test_df['class'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-14T03:16:20.920948Z",
     "iopub.status.busy": "2024-12-14T03:16:20.920337Z",
     "iopub.status.idle": "2024-12-14T03:16:20.930348Z",
     "shell.execute_reply": "2024-12-14T03:16:20.929443Z",
     "shell.execute_reply.started": "2024-12-14T03:16:20.920911Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class BindingAffinityModel(nn.Module):\n",
    "    def __init__(self, size, blosum_embedding_dim, lstm_hidden_dim=128, ffn_hidden_dim=256):\n",
    "        super(BindingAffinityModel, self).__init__()\n",
    "        self.n_dim = size\n",
    "        \n",
    "        # LSTM branch for BLOSUM embeddings of TCR sequences\n",
    "        self.tcr_lstm = nn.LSTM(input_size=blosum_embedding_dim, \n",
    "                                hidden_size=lstm_hidden_dim, \n",
    "                                num_layers=1, \n",
    "                                batch_first=True, \n",
    "                                bidirectional=True)\n",
    "        \n",
    "        # LSTM branch for BLOSUM embeddings of epitope sequences\n",
    "        self.epitope_lstm = nn.LSTM(input_size=blosum_embedding_dim, \n",
    "                                    hidden_size=lstm_hidden_dim, \n",
    "                                    num_layers=1, \n",
    "                                    batch_first=True, \n",
    "                                    bidirectional=True)\n",
    "        \n",
    "        # Branch A (FFN for TCR embeddings)\n",
    "        self.branchA = nn.Sequential(\n",
    "            nn.Linear(self.n_dim, self.n_dim * 2),\n",
    "            nn.BatchNorm1d(self.n_dim * 2),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.SiLU()\n",
    "        )\n",
    "        \n",
    "        # Branch B (FFN for epitope embeddings)\n",
    "        self.branchB = nn.Sequential(\n",
    "            nn.Linear(self.n_dim, self.n_dim * 2),\n",
    "            nn.BatchNorm1d(self.n_dim * 2),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.SiLU()\n",
    "        )\n",
    "        \n",
    "        # Combined FFN layers\n",
    "        self.combined = nn.Sequential(\n",
    "            nn.Linear(self.n_dim * 2 * 2 + 4 * lstm_hidden_dim, self.n_dim),\n",
    "            nn.BatchNorm1d(self.n_dim),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(self.n_dim, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, tcr_blosum_seq, epitope_blosum_seq, inputA, inputB):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        - tcr_blosum_seq: Tensor [batch_size, seq_len, blosum_embedding_dim] (BLOSUM TCR)\n",
    "        - epitope_blosum_seq: Tensor [batch_size, seq_len, blosum_embedding_dim] (BLOSUM Epitope)\n",
    "        - inputA: Tensor [batch_size, size] (TCR BERT Embedding)\n",
    "        - inputB: Tensor [batch_size, size] (Epitope BERT Embedding)\n",
    "        \"\"\"\n",
    "        # Process TCR BLOSUM sequence through LSTM\n",
    "        tcr_lstm_out, _ = self.tcr_lstm(tcr_blosum_seq)  # Shape: [batch_size, seq_len, 2*lstm_hidden_dim]\n",
    "        tcr_lstm_out = tcr_lstm_out[:, -1, :]  # Take last hidden state\n",
    "        \n",
    "        # Process Epitope BLOSUM sequence through LSTM\n",
    "        epitope_lstm_out, _ = self.epitope_lstm(epitope_blosum_seq)  # Shape: [batch_size, seq_len, 2*lstm_hidden_dim]\n",
    "        epitope_lstm_out = epitope_lstm_out[:, -1, :]  # Take last hidden state\n",
    "        \n",
    "        # Process BERT embeddings through FFN branches\n",
    "        x = self.branchA(inputA)  # Shape: [batch_size, n_dim * 2]\n",
    "        y = self.branchB(inputB)  # Shape: [batch_size, n_dim * 2]\n",
    "        \n",
    "        # Concatenate LSTM outputs with branch outputs\n",
    "        combined = torch.cat((x, y, tcr_lstm_out, epitope_lstm_out), dim=1)  # Shape: [batch_size, n_dim*4 + 4*lstm_hidden_dim]\n",
    "        \n",
    "        # Pass through combined FFN\n",
    "        z = self.combined(combined)  # Final output\n",
    "        return z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-14T03:16:26.736215Z",
     "iopub.status.busy": "2024-12-14T03:16:26.735897Z",
     "iopub.status.idle": "2024-12-14T03:21:23.511707Z",
     "shell.execute_reply": "2024-12-14T03:21:23.510783Z",
     "shell.execute_reply.started": "2024-12-14T03:16:26.736189Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score\n",
    "FFnmodel = BindingAffinityModel(768, 24).to(device)\n",
    "optimizer = torch.optim.Adam(FFnmodel.parameters(), lr=0.001)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(5):\n",
    "    FFnmodel.train()\n",
    "    epoch_loss = 0\n",
    "    train_preds, train_labels = [], []\n",
    "    \n",
    "    for tcr, epi, tcr_blosum, epi_blosum, label in tqdm(train_loader, desc=f\"Epoch {epoch+1}\"):\n",
    "        tcr, epi, label,tcr_blosum, epi_blosum = tcr.to(device), epi.to(device), label.to(device), tcr_blosum.to(device), epi_blosum.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = FFnmodel(tcr_blosum, epi_blosum,tcr, epi).squeeze()\n",
    "        loss = criterion(outputs, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        train_preds.extend(outputs.detach().cpu().numpy())\n",
    "        train_labels.extend(label.cpu().numpy())\n",
    "\n",
    "    # Metrics\n",
    "    train_preds_binary = [1 if p >= 0.5 else 0 for p in train_preds]\n",
    "    acc = accuracy_score(train_labels, train_preds_binary)\n",
    "    prec = precision_score(train_labels, train_preds_binary)\n",
    "    rec = recall_score(train_labels, train_preds_binary)\n",
    "    auc = roc_auc_score(train_labels, train_preds)\n",
    "\n",
    "    print(f\"Epoch {epoch+1} - Loss: {epoch_loss/len(train_loader):.4f}, Acc: {acc:.4f}, Prec: {prec:.4f}, Rec: {rec:.4f}, AUC: {auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-14T03:21:44.031683Z",
     "iopub.status.busy": "2024-12-14T03:21:44.030990Z",
     "iopub.status.idle": "2024-12-14T03:21:53.795790Z",
     "shell.execute_reply": "2024-12-14T03:21:53.795021Z",
     "shell.execute_reply.started": "2024-12-14T03:21:44.031641Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "FFnmodel.eval()\n",
    "test_preds, test_labels = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for tcr, epi, tcr_blosum, epi_blosum, label in tqdm(test_loader, desc=\"Testing\"):\n",
    "        tcr, epi, label, tcr_blosum, epi_blosum = tcr.to(device), epi.to(device), label.to(device), tcr_blosum.to(device), epi_blosum.to(device)\n",
    "        outputs = FFnmodel(tcr_blosum, epi_blosum, tcr, epi).squeeze()\n",
    "        test_preds.extend(outputs.cpu().numpy())\n",
    "        test_labels.extend(label.cpu().numpy())\n",
    "\n",
    "# Test metrics\n",
    "test_preds_binary = [1 if p >= 0.5 else 0 for p in test_preds]\n",
    "acc = accuracy_score(test_labels, test_preds_binary)\n",
    "prec = precision_score(test_labels, test_preds_binary)\n",
    "rec = recall_score(test_labels, test_preds_binary)\n",
    "auc = roc_auc_score(test_labels, test_preds)\n",
    "\n",
    "print(f\"Test Metrics - Acc: {acc:.4f}, Prec: {prec:.4f}, Rec: {rec:.4f}, AUC: {auc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "def cross_validate(dat, pep_blosum, tcr_blosum, n_splits=5, epochs=5, batch_size=32, learning_rate=0.001):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    labels = dat['class'].tolist()\n",
    "    \n",
    "    cv_results = {\n",
    "        'fold_accuracies': [],\n",
    "        'fold_precisions': [],\n",
    "        'fold_recalls': [],\n",
    "        'fold_aucs': [],\n",
    "        'cv_accuracy_mean': 0,\n",
    "        'cv_accuracy_std': 0,\n",
    "        'cv_precision_mean': 0,\n",
    "        'cv_precision_std': 0,\n",
    "        'cv_recall_mean': 0,\n",
    "        'cv_recall_std': 0,\n",
    "        'cv_auc_mean': 0,\n",
    "        'cv_auc_std': 0\n",
    "    }\n",
    "    \n",
    "    # Stratified K-Fold\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    \n",
    "    for fold, (train_index, val_index) in enumerate(skf.split(dat, labels), 1):\n",
    "        print(f\"\\n--- Fold {fold} ---\")\n",
    "\n",
    "        train_df = dat.iloc[train_index]\n",
    "        val_df = dat.iloc[val_index]\n",
    "        \n",
    "        train_pep = [pep_blosum[i] for i in train_index]\n",
    "        val_pep = [pep_blosum[i] for i in val_index]\n",
    "        train_tcr = [tcr_blosum[i] for i in train_index]\n",
    "        val_tcr = [tcr_blosum[i] for i in val_index]\n",
    "        \n",
    "        train_dataset = TCRDataset(\n",
    "            train_df['tcr_embeds'].tolist(),\n",
    "            train_df['epi_embeds'].tolist(),\n",
    "            train_pep,\n",
    "            train_tcr,\n",
    "            train_df['class'].tolist()\n",
    "        )\n",
    "        \n",
    "        val_dataset = TCRDataset(\n",
    "            val_df['tcr_embeds'].tolist(),\n",
    "            val_df['epi_embeds'].tolist(),\n",
    "            val_pep,\n",
    "            val_tcr,\n",
    "            val_df['class'].tolist()\n",
    "        )\n",
    "        \n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "        \n",
    "        model = BindingAffinityModel(768, 24).to(device)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "        criterion = nn.BCELoss()\n",
    "        \n",
    "        # Training loop\n",
    "        for epoch in range(epochs):\n",
    "            model.train()\n",
    "            train_loss = 0\n",
    "            train_preds, train_labels = [], []\n",
    "            \n",
    "            for tcr, epi, tcr_blosum, epi_blosum, label in tqdm(train_loader, desc=f\"Fold {fold}, Epoch {epoch+1}\"):\n",
    "                tcr = tcr.to(device)\n",
    "                epi = epi.to(device)\n",
    "                label = label.to(device)\n",
    "                tcr_blosum = tcr_blosum.to(device)\n",
    "                epi_blosum = epi_blosum.to(device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(tcr_blosum, epi_blosum, tcr, epi).squeeze()\n",
    "                loss = criterion(outputs, label)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                train_loss += loss.item()\n",
    "                train_preds.extend(outputs.detach().cpu().numpy())\n",
    "                train_labels.extend(label.cpu().numpy())\n",
    "            \n",
    "            # Validation\n",
    "            model.eval()\n",
    "            val_preds, val_labels = [], []\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for tcr, epi, tcr_blosum, epi_blosum, label in val_loader:\n",
    "                    tcr = tcr.to(device)\n",
    "                    epi = epi.to(device)\n",
    "                    label = label.to(device)\n",
    "                    tcr_blosum = tcr_blosum.to(device)\n",
    "                    epi_blosum = epi_blosum.to(device)\n",
    "                    \n",
    "                    outputs = model(tcr_blosum, epi_blosum, tcr, epi).squeeze()\n",
    "                    val_preds.extend(outputs.cpu().numpy())\n",
    "                    val_labels.extend(label.cpu().numpy())\n",
    "\n",
    "            val_preds_binary = [1 if p >= 0.5 else 0 for p in val_preds]\n",
    "            fold_acc = accuracy_score(val_labels, val_preds_binary)\n",
    "            fold_prec = precision_score(val_labels, val_preds_binary)\n",
    "            fold_rec = recall_score(val_labels, val_preds_binary)\n",
    "            fold_auc = roc_auc_score(val_labels, val_preds)\n",
    "            \n",
    "            print(f\"Fold {fold}, Epoch {epoch+1} - Val Metrics:\")\n",
    "            print(f\"Loss: {train_loss/len(train_loader):.4f}\")\n",
    "            print(f\"Accuracy: {fold_acc:.4f}\")\n",
    "            print(f\"Precision: {fold_prec:.4f}\")\n",
    "            print(f\"Recall: {fold_rec:.4f}\")\n",
    "            print(f\"AUC: {fold_auc:.4f}\")\n",
    "        \n",
    "        cv_results['fold_accuracies'].append(fold_acc)\n",
    "        cv_results['fold_precisions'].append(fold_prec)\n",
    "        cv_results['fold_recalls'].append(fold_rec)\n",
    "        cv_results['fold_aucs'].append(fold_auc)\n",
    "\n",
    "    cv_results['cv_accuracy_mean'] = np.mean(cv_results['fold_accuracies'])\n",
    "    cv_results['cv_accuracy_std'] = np.std(cv_results['fold_accuracies'])\n",
    "    cv_results['cv_precision_mean'] = np.mean(cv_results['fold_precisions'])\n",
    "    cv_results['cv_precision_std'] = np.std(cv_results['fold_precisions'])\n",
    "    cv_results['cv_recall_mean'] = np.mean(cv_results['fold_recalls'])\n",
    "    cv_results['cv_recall_std'] = np.std(cv_results['fold_recalls'])\n",
    "    cv_results['cv_auc_mean'] = np.mean(cv_results['fold_aucs'])\n",
    "    cv_results['cv_auc_std'] = np.std(cv_results['fold_aucs'])\n",
    "\n",
    "    print(\"\\n--- Cross-Validation Summary ---\")\n",
    "    print(f\"Accuracy: {cv_results['cv_accuracy_mean']:.4f} ± {cv_results['cv_accuracy_std']:.4f}\")\n",
    "    print(f\"Precision: {cv_results['cv_precision_mean']:.4f} ± {cv_results['cv_precision_std']:.4f}\")\n",
    "    print(f\"Recall: {cv_results['cv_recall_mean']:.4f} ± {cv_results['cv_recall_std']:.4f}\")\n",
    "    print(f\"AUC: {cv_results['cv_auc_mean']:.4f} ± {cv_results['cv_auc_std']:.4f}\")\n",
    "    \n",
    "    return cv_results\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6269395,
     "sourceId": 10154626,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6269805,
     "sourceId": 10155208,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6296017,
     "sourceId": 10190390,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6296753,
     "sourceId": 10191365,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6298681,
     "sourceId": 10193955,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30805,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
